{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a211d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the CPU to train the model.\n",
    "# ignore it if GPU memory is sufficient.\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ea18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter.\n",
    "\n",
    "Epochs       = 60\n",
    "Batch_size   = 32\n",
    "Channels     = 9                          # representing 9 electron orbitals\n",
    "Split_ratio  = 0.2\n",
    "Seed         = 34596                      # random seed to split data\n",
    "#Seed         = np.random.randint(1, 1e6)\n",
    "Orbitals     = ['s','py','pz','pz','dxy','dyz','dz2','dxz','dx2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Reshape, BatchNormalization\n",
    "from keras.layers import (\n",
    "    Conv1D,\n",
    "    GlobalAveragePooling1D,\n",
    "    MaxPooling1D,\n",
    "    GlobalAveragePooling1D,\n",
    "    Reshape,\n",
    "    AveragePooling1D,\n",
    "    Flatten,\n",
    "    Concatenate,\n",
    ")\n",
    "from keras import backend\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "# the model for feature extraction\n",
    "def dos_featurizer(channels):\n",
    "    # the input data is a 2000*9 matrix\n",
    "    input_DOS = Input( shape=(2000,channels) )\n",
    "    # building a feature extraction network\n",
    "    feature1 = AveragePooling1D(pool_size=  4,strides=4,padding=\"same\")(input_DOS)\n",
    "    feature2 = AveragePooling1D(pool_size= 25,strides=4,padding=\"same\")(input_DOS)\n",
    "    feature3 = AveragePooling1D(pool_size=200,strides=4,padding=\"same\")(input_DOS)\n",
    "    Feature  = Concatenate(axis=-1)([feature1,feature2,feature3])                   # splicing\n",
    "    Feature  = Conv1D( 50,20,activation=\"relu\", padding=\"same\", strides=2)(Feature) # convolution\n",
    "    Feature  = BatchNormalization()(Feature)                                        # normalization\n",
    "    Feature  = Conv1D( 75, 3,activation=\"relu\",padding=\"same\",strides=2)(Feature)   # convolution\n",
    "    Feature  = AveragePooling1D(pool_size=3,strides=2,padding=\"same\")(Feature)      # pooling\n",
    "    Feature  = Conv1D(100, 3,activation=\"relu\",padding=\"same\",strides=2)(Feature)   # convolution\n",
    "    Feature  = AveragePooling1D(pool_size=3,strides=2,padding=\"same\")(Feature)      # pooling\n",
    "    Feature  = Conv1D(125, 3,activation=\"relu\",padding=\"same\",strides=2)(Feature)   # convolution\n",
    "    Feature  = AveragePooling1D(pool_size=3,strides=2,padding=\"same\")(Feature)      # pooling\n",
    "    Feature  = Conv1D(150, 3,activation=\"relu\",padding=\"same\",strides=1)(Feature)   # convolution\n",
    "    Featurizer_model = Model( input_dos, Feature )                                  # modeling\n",
    "    return Featurizer_model\n",
    "\n",
    "# the model for prediction\n",
    "def create_model(Featurizer, channels):\n",
    "    # data on 3 layers of topology structure\n",
    "    input1 = Input( shape=(2000,channels) )\n",
    "    input2 = Input( shape=(2000,channels) )\n",
    "    input3 = Input( shape=(2000,channels) )\n",
    "    # feature extraction\n",
    "    output1 = Featurizer(input1)\n",
    "    output2 = Featurizer(input2)\n",
    "    output3 = Featurizer(input3)\n",
    "    Output = Concatenate(axis=-1)([output1,output2,output3])\n",
    "    Output = Flatten()(Output)\n",
    "    Output = Dropout(0.2)(Output)\n",
    "    Output = Dense(1000,activation=\"linear\")(Output)\n",
    "    Output = Dense(2200,activation=\"relu\"  )(Output)\n",
    "    Output = Dense(2200,activation=\"relu\"  )(Output)\n",
    "    # modeling\n",
    "    model = Model( inputs=[input1,input2,input3],outputs=Output )\n",
    "    return model\n",
    "\n",
    "# learning function\n",
    "def decay_schedule(epoch, lr):\n",
    "    if   epoch== 0: lr = 0.00100\n",
    "    elif epoch==15: lr = 0.00050\n",
    "    elif epoch==35: lr = 0.00010\n",
    "    elif epoch==45: lr = 0.00005\n",
    "    elif epoch==55: lr = 0.00001\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19814da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "with open('DataToPredictDOS','rb') as One:\n",
    "    x_in = pickle.load(One)\n",
    "    y_in = pickle.load(One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca0f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "#if you want to predict DOS without training the model by yourself, skip this step#\n",
    "#                  ,or download data following \"Readme\".                          #\n",
    "###################################################################################\n",
    "# storing predict data\n",
    "# predict_dos = np.zeros([x_in_unpredict.shape[0],2200,9])\n",
    "\n",
    "# train\n",
    "for i in range(9):\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_in,\n",
    "                                                        y_in[:,:,i+1],\n",
    "                                                        test_size=Split_ratio, \n",
    "                                                        random_state=Seed\n",
    "                                                       )\n",
    "    shared_conv  = dos_featurizer(Channels)\n",
    "    lr_scheduler = LearningRateScheduler(decay_schedule, verbose=0)\n",
    "    tensorboard  = TensorBoard(log_dir=\"logs/{}\".format(time.time()),histogram_freq=1)\n",
    "    model = create_model(shared_conv, Channels)\n",
    "    model.compile(loss=\"logcosh\",optimizer=Adam(0.001),metrics=[\"mean_absolute_error\"])\n",
    "    model.summary()\n",
    "    model.fit([x_train[:,:,0:9],x_train[:,:,9:18],x_train[:,:,18:27]],\n",
    "              y_train,\n",
    "              batch_size=Batch_size,\n",
    "              epochs=Epochs,\n",
    "              validation_data=([x_test[:,:,0:9], x_test[:,:,9:18], x_test[:,:,18:27]],y_test),\n",
    "              callbacks=[tensorboard, lr_scheduler],\n",
    "             )\n",
    "        \n",
    "    train_out = model.predict([x_train[:,:,0:9],x_train[:,:,9:18],x_train[:,:,18:27]])\n",
    "    train_out = train_out.reshape(train_out.shape)\n",
    "    test_out  = model.predict([ x_test[:,:,0:9], x_test[:,:,9:18], x_test[:,:,18:27]])\n",
    "    test_out  =  test_out.reshape( test_out.shape)\n",
    "\n",
    "    print(\"train MAE :\", mean_absolute_error(y_train, train_out))\n",
    "    print(\"train RMSE:\",  mean_squared_error(y_train, train_out)**(0.5))\n",
    "    print(\"test  MAE :\", mean_absolute_error( y_test,  test_out))\n",
    "    print(\"test  RMSE:\",  mean_squared_error( y_test,  test_out)**(0.5))\n",
    "    \n",
    "    print(\"Saving model...\")\n",
    "    model.save('Model/predict_DOS_'+Orbitals[i]+'.h5')\n",
    "    \n",
    "    #predict_dos[:,:,i] = model.predict([x_in_unpredict[:, :, 0:9], x_in_unpredict[:, :, 9:18], x_in_unpredict[:, :, 18:27]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# Please provide input according to your needs, or use example #\n",
    "################################################################\n",
    "# provide input data for prediction.\n",
    "# according to the introduction of the paper,\n",
    "# provided DOS data for 9 electron orbitals (s,py,pz,pz,dxy,dyz,dz2,dxz,dx2) of 3 layers \n",
    "# has an accuracy of 0.01eV within Â±10eV, to make a 2000*27 matrix.\n",
    "\n",
    "# our example:\n",
    "List = np.arange(x_in.shape[0])\n",
    "np.random.shuffle(List)\n",
    "x_in_unpredict = x_in[List[0:100]]\n",
    "#y_in_unpredict = y_in[List[0:100]]  # open it if you want compare the data and prediction\n",
    "\n",
    "predict_dos = np.zeros([x_in_unpredict.shape[0],2200,9])\n",
    "for i in range(9):\n",
    "    Model = load_model('Model/predict_DOS_'+Orbitals[i]+'.h5')\n",
    "    predict_dos[:,:,i] = Model.predict([x_in_unpredict[:, :, 0:9],x_in_unpredict[:, :, 9:18],x_in_unpredict[:, :, 18:27]])\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
